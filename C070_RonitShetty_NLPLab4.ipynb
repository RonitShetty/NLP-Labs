{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMX1FFV0OJvjTAFIo+IKcse",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RonitShetty/NLP-Labs/blob/main/C070_RonitShetty_NLPLab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP Lab 4\n",
        "**Roll No.:** C070  \n",
        "**Name:** Ronit Shetty  \n",
        "**SAP ID:** 70322000128  \n",
        "**Division:** C  \n",
        "**Batch:** C1  "
      ],
      "metadata": {
        "id": "_c8ROFyClyUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###B.1 Tasks"
      ],
      "metadata": {
        "id": "mZI-6zMvqy0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install necessary libraries in the Colab environment\n",
        "!pip install requests beautifulsoup4 pandas\n",
        "\n",
        "# Step 2: Import libraries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Step 3: Define the URL and send the HTTP request\n",
        "# This is a website designed for scraping, so it's very reliable.\n",
        "URL = \"http://quotes.toscrape.com\"\n",
        "webpage = requests.get(URL)\n",
        "soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
        "\n",
        "# Step 4: Find all the containers for each quote\n",
        "# By inspecting the page, we can see each quote is in a <div class=\"quote\">\n",
        "quote_containers = soup.find_all(\"div\", class_=\"quote\")\n",
        "\n",
        "# Step 5: Initialize lists to store the scraped data\n",
        "all_quotes = []\n",
        "all_authors = []\n",
        "all_tags = []\n",
        "\n",
        "# Step 6: Loop through each quote container and extract the relevant information\n",
        "for quote in quote_containers:\n",
        "    # Extract the quote's text, which is in a <span class=\"text\">\n",
        "    text = quote.find(\"span\", class_=\"text\").get_text(strip=True)\n",
        "\n",
        "    # Extract the author's name, which is in a <small class=\"author\">\n",
        "    author = quote.find(\"small\", class_=\"author\").get_text(strip=True)\n",
        "\n",
        "    # Find the container for tags, which is a <div class=\"tags\">\n",
        "    tags_div = quote.find(\"div\", class_=\"tags\")\n",
        "    # Inside that div, find all the <a> tags and get their text\n",
        "    tags = [tag.get_text(strip=True) for tag in tags_div.find_all(\"a\", class_=\"tag\")]\n",
        "    # Join the list of tags into a single comma-separated string\n",
        "    tags_str = \", \".join(tags)\n",
        "\n",
        "    # Add the extracted data to our lists\n",
        "    all_quotes.append(text)\n",
        "    all_authors.append(author)\n",
        "    all_tags.append(tags_str)\n",
        "\n",
        "\n",
        "# Step 7: Create a Pandas DataFrame to display the data neatly\n",
        "df = pd.DataFrame({\n",
        "    'Quote': all_quotes,\n",
        "    'Author': all_authors,\n",
        "    'Tags': all_tags\n",
        "})\n",
        "\n",
        "# Display the results\n",
        "print(\"--- Scraped Quotes from http://quotes.toscrape.com ---\")\n",
        "print(df.to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHUl8sPyl5sc",
        "outputId": "fec04638-eae7-43ca-af80-89d2e8600b0f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.14.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "--- Scraped Quotes from http://quotes.toscrape.com ---\n",
            "                                                                                                                                 Quote             Author                                          Tags\n",
            "0                  “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”    Albert Einstein        change, deep-thoughts, thinking, world\n",
            "1                                                “It is our choices, Harry, that show what we truly are, far more than our abilities.”       J.K. Rowling                            abilities, choices\n",
            "2  “There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”    Albert Einstein  inspirational, life, live, miracle, miracles\n",
            "3                             “The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”        Jane Austen              aliteracy, books, classic, humor\n",
            "4                      “Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”     Marilyn Monroe                    be-yourself, inspirational\n",
            "5                                                                  “Try not to become a man of success. Rather become a man of value.”    Albert Einstein                     adulthood, success, value\n",
            "6                                                   “It is better to be hated for what you are than to be loved for what you are not.”         André Gide                                    life, love\n",
            "7                                                                    “I have not failed. I've just found 10,000 ways that won't work.”   Thomas A. Edison   edison, failure, inspirational, paraphrased\n",
            "8                                                “A woman is like a tea bag; you never know how strong it is until it's in hot water.”  Eleanor Roosevelt               misattributed-eleanor-roosevelt\n",
            "9                                                                                   “A day without sunshine is like, you know, night.”       Steve Martin                        humor, obvious, simile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install Tesseract OCR engine and the Python wrapper in Colab\n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "\n",
        "# Step 2: Import necessary libraries\n",
        "import pytesseract\n",
        "from PIL import Image # Pillow library for image handling\n",
        "import requests # To download the image from a URL\n",
        "\n",
        "# Step 3: Download an image with text to process\n",
        "image_url = 'https://www.aplustopper.com/media/images/articles/Merchant-of-Venice-Act-1-Scene-1-Translation-Meaning-Annotations-1.png'\n",
        "\n",
        "img = Image.open(requests.get(image_url, stream=True).raw)\n",
        "\n",
        "# Display the image (optional, for verification in a notebook)\n",
        "# img.show() # In Colab, you'd use from google.colab.patches import cv2_imshow; cv2_imshow(img)\n",
        "\n",
        "# Step 4: Use pytesseract to perform OCR on the image\n",
        "# The image_to_string function takes an image object and returns the extracted text\n",
        "extracted_text = pytesseract.image_to_string(img)\n",
        "\n",
        "# Step 5: Print the extracted text\n",
        "print(\"--- Extracted Text ---\")\n",
        "print(extracted_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sYUDN4OmDy6",
        "outputId": "37d2396b-cfbf-44ad-9a55-4a904b06c5a4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (25.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.3.0)\n",
            "--- Extracted Text ---\n",
            "[Venice - A street]\n",
            "\n",
            "Enter Antonio, SALARINO, and SALANIO.\n",
            "\n",
            "ANTONIO: Jn sooth, I know not why I am so\n",
            "sad;\n",
            "\n",
            "It wearies me; you say it wearies you;\n",
            "\n",
            "But how I caught it, found it, or came by it,\n",
            "What stuff ’tis made of, whereof it is born,\n",
            "Tam to learn;(5)\n",
            "\n",
            "And such a want-wit sadness makes of me,\n",
            "That I have much ado to know myself.\n",
            "\n",
            "SALARINO: Your mind is tossing on the ocean;\n",
            "There, where your argosies, with portly sail,\n",
            "Like signiors and rich burghers on the flood, (10)\n",
            "Or, as it were, the pageants of the sea,\n",
            "\n",
            "Do overpeer the petty traffickers,\n",
            "\n",
            "That curt sy to them, do them reverence,\n",
            "\n",
            "As they fly by them with their woven wings.\n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B.2 Observations and Learning\n",
        "\n",
        "Text acquisition is highly dependent on the source's structure. For web scraping with **Beautiful Soup**, success hinges on correctly identifying **HTML tags** and **attributes** using a browser's inspection tools, and I learned that scrapers are fragile and can break if a website's layout changes. Using headers like `User-Agent` is essential to prevent being blocked. For OCR with **Tesseract**, I observed that the **quality of the input image is paramount**. While it worked well on clean, machine-printed text, it's clear that significant image preprocessing would be required for noisy or complex images to ensure accurate text extraction.\n",
        "\n",
        "### B.3 Conclusion\n",
        "\n",
        "I learned how to apply fundamental text acquisition techniques and successfully achieved the experiment's outcomes. I implemented a solution using the **Beautiful Soup** library to parse and scrape structured data from a live website and utilized the **Tesseract OCR engine** to extract and digitize text from an image file. This lab provided direct, hands-on experience in gathering raw text from different sources, solidifying my understanding of the initial data collection phase of an NLP project."
      ],
      "metadata": {
        "id": "iNzmmVekqoK_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B.4 Questions of Curiosity\n",
        "\n",
        "1.  **How does one parse the HTML into a `BeautifulSoup` object given a `response` object?**\n",
        "    \n",
        "    *Ans: To parse an HTML `response` object, I create a `BeautifulSoup` object by passing the response content and a parser: `soup = BeautifulSoup(response.content, 'html.parser')`.*\n",
        "\n",
        "2.  **Given that `soup.find_all(class_='items')` returns a list, in order to get the first item, all you need to do is index. (True/False)**\n",
        "    \n",
        "    *Ans: **True**. To get the first item from the list-like object returned by `soup.find_all()`, I can use index `[0]`.*\n",
        "\n",
        "3.  **Given the below html, how would this tag type be described in web scraping code? `<h1 class='sports'>Sports News</h1>`**\n",
        "    \n",
        "    *Ans: The tag `<h1 class='sports'>Sports News</h1>` is an `<h1>` tag with a `class` attribute of `'sports'`. I would locate it in code with a command like `soup.find('h1', class_='sports')`.*\n",
        "\n",
        "4.  **List 3 Disadvantages of using Tesseract.**\n",
        "    \n",
        "    *Ans: Three disadvantages of Tesseract are: 1) High sensitivity to image quality, performing poorly on low-resolution or noisy images. 2) Difficulty interpreting complex page layouts like multiple columns. 3) Poor accuracy on non-standard fonts or handwritten text.*"
      ],
      "metadata": {
        "id": "uk5Fdcvcoqb4"
      }
    }
  ]
}
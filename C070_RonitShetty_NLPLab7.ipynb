{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMk1S4DAZJqSQm/aiRz3yvU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RonitShetty/NLP-Labs/blob/main/C070_RonitShetty_NLPLab7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP Lab 7\n",
        "****\n",
        "**Aim:** Identify the Named Entity Recognition (NER) in text data.\n",
        "\n",
        "**Roll No.:** C070  \n",
        "**Name:** Ronit Shetty  \n",
        "**SAP ID:** 70322000128  \n",
        "**Division:** C  \n",
        "**Batch:** C1  "
      ],
      "metadata": {
        "id": "M87FkZR1wZJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install spaCy library and download the small English model\n",
        "!pip install -q spacy\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z645Tj6IwfTx",
        "outputId": "62adca10-8c3b-46cc-b573-e99c8066d152"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m107.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implementing NER with spaCy\n",
        "\n",
        "This task uses the spaCy library to identify named entities. spaCy is a modern and efficient library for production-level NLP tasks."
      ],
      "metadata": {
        "id": "iURdDQ1fxrWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the pre-trained English language model\n",
        "# 'en_core_web_sm' is a small English model trained on written web text.\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Define the text to be analyzed\n",
        "text = \"\"\"\n",
        "Apple Inc., a technology company founded by Steve Jobs, is reportedly looking to acquire a U.K. startup for over $1 billion.\n",
        "The deal is expected to be finalized by next Tuesday in London. Sundar Pichai, the CEO of Google, commented on the market trends.\n",
        "\"\"\"\n",
        "\n",
        "# Process the text with the spaCy NLP pipeline\n",
        "doc = nlp(text)\n",
        "\n",
        "# Print the identified named entities, their labels, and an explanation of the label.\n",
        "print(\"--- Identified Named Entities ---\")\n",
        "for ent in doc.ents:\n",
        "    print(f\"Entity: {ent.text:<15} | Label: {ent.label_:<10} | Explanation: {spacy.explain(ent.label_)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAN2JLJEwpgk",
        "outputId": "45f0ef4e-4645-44d5-c783-063bba9b3324"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Identified Named Entities ---\n",
            "Entity: Apple Inc.      | Label: ORG        | Explanation: Companies, agencies, institutions, etc.\n",
            "Entity: Steve Jobs      | Label: PERSON     | Explanation: People, including fictional\n",
            "Entity: U.K.            | Label: GPE        | Explanation: Countries, cities, states\n",
            "Entity: over $1 billion | Label: MONEY      | Explanation: Monetary values, including unit\n",
            "Entity: next Tuesday    | Label: DATE       | Explanation: Absolute or relative dates or periods\n",
            "Entity: London          | Label: GPE        | Explanation: Countries, cities, states\n",
            "Entity: Sundar Pichai   | Label: PERSON     | Explanation: People, including fictional\n",
            "Entity: Google          | Label: ORG        | Explanation: Companies, agencies, institutions, etc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualizing Named Entities with displaCy\n",
        "\n",
        "A powerful feature of spaCy is its built-in visualizer, displaCy. It helps in presenting the NER results in a more human-readable format by highlighting the entities directly in the text."
      ],
      "metadata": {
        "id": "gLYHQZS0xyUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the displacy module from spaCy\n",
        "from spacy import displacy\n",
        "\n",
        "# Use displacy to render the NER output within a Jupyter/Colab notebook\n",
        "# The 'style=\"ent\"' option specifies that we want to visualize entities.\n",
        "displacy.render(doc, style=\"ent\", jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "kQ2ZTrZzwrfF",
        "outputId": "40bad7d8-1339-483c-9940-36b9ce5553a1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"><br>\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Apple Inc.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", a technology company founded by \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Steve Jobs\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", is reportedly looking to acquire a \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    U.K.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " startup for \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    over $1 billion\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              ".<br>The deal is expected to be finalized by \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    next Tuesday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    London\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ". \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Sundar Pichai\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", the CEO of \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Google\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", commented on the market trends.<br></div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implementing NER with NLTK\n",
        "\n",
        "This task demonstrates how to perform NER using another popular library, the Natural Language Toolkit (NLTK). The process in NLTK is more granular, typically requiring three steps: tokenization, Part-of-Speech (POS) tagging, and then chunking to find entities."
      ],
      "metadata": {
        "id": "gvarnhK-x7Lx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# NLTK requires downloading specific packages\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('maxent_ne_chunker_tab')\n",
        "nltk.download('words')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "print(\"\\n--- Task 3: Identifying Named Entities using NLTK ---\")\n",
        "\n",
        "# 1. Tokenize the sentence into words\n",
        "tokenized_text = nltk.word_tokenize(text)\n",
        "\n",
        "# 2. Apply Part-of-Speech (POS) tagging to the tokenized words\n",
        "pos_tagged_text = nltk.pos_tag(tokenized_text)\n",
        "\n",
        "# 3. Apply Named Entity chunking\n",
        "# The 'binary=True' parameter groups all named entities under a single 'NE' label\n",
        "named_entities_tree = nltk.ne_chunk(pos_tagged_text)\n",
        "\n",
        "print(named_entities_tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rKAUGlpxOVr",
        "outputId": "36790373-8dd6-4e19-c735-e957b556ac1d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Task 3: Identifying Named Entities using NLTK ---\n",
            "(S\n",
            "  (PERSON Apple/NNP)\n",
            "  (ORGANIZATION Inc./NNP)\n",
            "  ,/,\n",
            "  a/DT\n",
            "  technology/NN\n",
            "  company/NN\n",
            "  founded/VBN\n",
            "  by/IN\n",
            "  (PERSON Steve/NNP Jobs/NNP)\n",
            "  ,/,\n",
            "  is/VBZ\n",
            "  reportedly/RB\n",
            "  looking/VBG\n",
            "  to/TO\n",
            "  acquire/VB\n",
            "  a/DT\n",
            "  U.K./NNP\n",
            "  startup/NN\n",
            "  for/IN\n",
            "  over/IN\n",
            "  $/$\n",
            "  1/CD\n",
            "  billion/CD\n",
            "  ./.\n",
            "  The/DT\n",
            "  deal/NN\n",
            "  is/VBZ\n",
            "  expected/VBN\n",
            "  to/TO\n",
            "  be/VB\n",
            "  finalized/VBN\n",
            "  by/IN\n",
            "  next/JJ\n",
            "  Tuesday/NNP\n",
            "  in/IN\n",
            "  (GPE London/NNP)\n",
            "  ./.\n",
            "  (PERSON Sundar/NNP Pichai/NNP)\n",
            "  ,/,\n",
            "  the/DT\n",
            "  (ORGANIZATION CEO/NNP)\n",
            "  of/IN\n",
            "  (GPE Google/NNP)\n",
            "  ,/,\n",
            "  commented/VBD\n",
            "  on/IN\n",
            "  the/DT\n",
            "  market/NN\n",
            "  trends/NNS\n",
            "  ./.)\n"
          ]
        }
      ]
    }
  ]
}